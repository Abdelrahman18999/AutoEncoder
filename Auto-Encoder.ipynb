{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, ReLU, Conv2D, Conv2DTranspose, Activation\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(inputs, layers):\n",
    "    \"\"\" Construct the Encoder\n",
    "    x: input to the encoder\n",
    "    layers: number of filters per layer\n",
    "    \"\"\"\n",
    "    outputs = inputs  \n",
    "    last_filters = layers.pop() # set a side the last layer\n",
    "    \n",
    "    # Feature Pooling\n",
    "    for n_filters in layers:\n",
    "        outputs = Conv2D(n_filters, (3,3), strides=(2,2), padding='same')(outputs)\n",
    "        outputs = BatchNormalization()(outputs)\n",
    "        outputs = ReLU()(outputs)\n",
    "    \n",
    "    # Adds sparsity constraints to last layer in encoder\n",
    "    outputs = Conv2D(last_filters, (3,3), strides=(2,2), padding='same', activity_regularizer = l1(1e-4))(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = ReLU()(outputs)\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(inputs, layers):\n",
    "    \"\"\" Construct the Decoder\n",
    "    inputs: input to the decoder\n",
    "    layers: the number of filters per layer (in encoder)\n",
    "    \"\"\"\n",
    "    outputs = inputs\n",
    "    \n",
    "    #Progressive feature unpooling (dimensionality expansion)\n",
    "    for _ in range(len(layers)-1, 0, -1):\n",
    "        n_filters = layers[_]\n",
    "        outputs = Conv2DTranspose(n_filters, (3,3), strides=(2,2), padding='same')(outputs)\n",
    "        outputs = BatchNormalization()(outputs)\n",
    "        outputs = ReLU()(outputs)\n",
    "        \n",
    "    # img_out_layers = 3 (colored image) and qual 1 if (gray scale)\n",
    "    # Last unpooling and restore to image input shape\n",
    "    outputs = Conv2DTranspose(img_out_layers, (3,3), strides=(2,2), padding='same')(outputs)\n",
    "    outputs = BatchNormalization()(outputs) \n",
    "    outputs = Activation('sigmoid')(outputs)\n",
    "    return outputs #The decoded image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [64, 32, 16]\n",
    "inputs = Input(shape=(rows, columns, channels))\n",
    "encoding = encoder(inputs, layers)\n",
    "outputs = decoder(encoding, layers)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the noise to a copy of the image training data\n",
    "x_train_noisy = x_train + noise\n",
    "\n",
    "# Trains the encoder by feeding the noisy images as the training data and the original images as the labels\n",
    "model.fit(x_train_noisy, x_train, epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
